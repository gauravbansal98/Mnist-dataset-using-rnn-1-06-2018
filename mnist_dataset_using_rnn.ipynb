{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist dataset using rnn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gauravbansal98/Mnist-dataset-using-rnn-1-06-2018/blob/master/mnist_dataset_using_rnn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "P61dlS1Fv8OE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PInJJ_Yv0Sgp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MXiZYsuD0Uje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hXaWAnEP0pAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"drive/mnist dataset using normal rnn\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZCGPO3G0rfo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/mixuala/colab_utils\n",
        "import colab_utils.tboard\n",
        "ROOT = %pwd\n",
        "print(ROOT)\n",
        "LOG_DIR = os.path.join(ROOT, 'gaurav')\n",
        "print(LOG_DIR)\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=LOG_DIR )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52zmzjXw5rby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops import rnn, rnn_cell\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQbfNpjt0ucL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rnn_size = 128\n",
        "no_of_nodes_in_output_layer = 10\n",
        "chunk_size = 28\n",
        "no_of_chunk = 28\n",
        "batch_size = 128\n",
        "hm_epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VflAwafR1hAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(dtype = tf.float32, shape = [None, no_of_chunk, chunk_size], name = \"input_labels\")\n",
        "y = tf.placeholder(dtype = tf.float32, shape = [None, None], name = \"output_labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWn_PCxl1kmt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = { 'weights' : tf.Variable(tf.random_normal([rnn_size, no_of_nodes_in_output_layer], name = 'weights')),\n",
        "           'biases' : tf.Variable(tf.random_normal([1, no_of_nodes_in_output_layer], name = 'biases')) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iKk4uX982WjT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recurrent_neural_network(x):\n",
        "  with tf.name_scope('Neural_Network'):\n",
        "    x = tf.transpose(x, [1,0,2])\n",
        "    x = tf.reshape(x, [-1, chunk_size])\n",
        "    x = tf.split(x, no_of_chunk, 0)\n",
        "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_size, name = 'LSTM_CELL')\n",
        "    outputs, state = tf.nn.static_rnn(cell, x, dtype = tf.float32)\n",
        "\n",
        "    output = tf.add(tf.matmul(outputs[-1], weights['weights']), weights['biases'])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_A8fcP3z3lgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network(x):\n",
        "\n",
        "  prediction = recurrent_neural_network(x)\n",
        "  \n",
        "  with tf.name_scope('cost'):\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
        "  summary = tf.summary.scalar('total_cost', cost)\n",
        "  \n",
        "  with tf.name_scope('optimizer'):\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  merged = tf.summary.merge_all()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    train_writer = tf.summary.FileWriter('./gaurav',sess.graph)\n",
        "    k = 0\n",
        "    for i in range(hm_epochs):\n",
        "      epoch_loss = 0\n",
        "      for j in range(int(mnist.train.num_examples/batch_size)):\n",
        "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "        epoch_x = epoch_x.reshape((batch_size,no_of_chunk,chunk_size))\n",
        "        o, c, m = sess.run([optimizer, cost, merged], feed_dict = {x : epoch_x, y : epoch_y})\n",
        "        epoch_loss += c\n",
        "        train_writer.add_summary(m, k)\n",
        "        k += 1\n",
        "      print('epoch' , i, 'completed out of ', hm_epochs, 'loss ', epoch_loss)\n",
        "      \n",
        "      \n",
        "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "  \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "  \n",
        "    print('Accuracy:',accuracy.eval({x:mnist.test.images.reshape(-1,no_of_chunk,chunk_size), y:mnist.test.labels})) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBU3aak24r9e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "3b1de52b-cc4a-4ac4-82bf-57c74f82703e"
      },
      "cell_type": "code",
      "source": [
        "train_neural_network(x)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 completed out of  20 loss  203.51496625691652\n",
            "epoch 1 completed out of  20 loss  58.848411567509174\n",
            "epoch 2 completed out of  20 loss  39.99966784613207\n",
            "epoch 3 completed out of  20 loss  29.94585596770048\n",
            "epoch 4 completed out of  20 loss  25.270001084078103\n",
            "epoch 5 completed out of  20 loss  20.602786916308105\n",
            "epoch 6 completed out of  20 loss  18.362319762585685\n",
            "epoch 7 completed out of  20 loss  15.69905512954574\n",
            "epoch 8 completed out of  20 loss  13.8019198164111\n",
            "epoch 9 completed out of  20 loss  13.79600096627837\n",
            "epoch 10 completed out of  20 loss  10.316648285952397\n",
            "epoch 11 completed out of  20 loss  9.803733514680061\n",
            "epoch 12 completed out of  20 loss  9.399962866213173\n",
            "epoch 13 completed out of  20 loss  8.765975842921762\n",
            "epoch 14 completed out of  20 loss  7.35447836513049\n",
            "epoch 15 completed out of  20 loss  7.398822996459785\n",
            "epoch 16 completed out of  20 loss  6.171237048285548\n",
            "epoch 17 completed out of  20 loss  6.797430321836146\n",
            "epoch 18 completed out of  20 loss  5.09359554664843\n",
            "epoch 19 completed out of  20 loss  5.883552197366953\n",
            "Accuracy: 0.9854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kgvsZTSg4uuG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}